{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amir-asari/Introduction_to_Huggingface/blob/main/2_UsingTransformers/2_Behind_the_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy_62n1pE16J"
      },
      "source": [
        "# Outline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5O84lqwE16L",
        "outputId": "195651fe-2004-4651-aad6-066a56da7dc0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598050713539124},\n",
              " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import transformers\n",
        "\n",
        "classifier = transformers.pipeline(\"sentiment-analysis\")\n",
        "classifier(\n",
        "    [\n",
        "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "        \"I hate this so much!\",\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjPJYSZbE16M"
      },
      "source": [
        "# Behind the Pipeline API\n",
        "\n",
        "3 Stage Pipeline  \n",
        "\n",
        "0. dataset\n",
        "1. language tokenizer -> word to it's unique number mapping\n",
        "2. pretrained_model   -> word id to it's meaning vector / embedding vector / hidden layer size\n",
        "3. model output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcgpgmkKE16M"
      },
      "source": [
        "## 1. initialize tokenizer & model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhcwRD5RE16N"
      },
      "outputs": [],
      "source": [
        "raw_inputs = [\n",
        "    \"I love you so much\",    # 5 Words\n",
        "    \"I hate you\",            # 2 Words\n",
        "    \"you\",                   # 1 Word\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZqM2MqdE16N",
        "outputId": "6f5b5316-1281-45a1-bf89-a0279104a888"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 101,  146, 1567, 1128, 1177, 1277,  102],\n",
            "        [ 101,  146, 4819, 1128,  102,    0,    0],\n",
            "        [ 101, 1128,  102,    0,    0,    0,    0]])\n"
          ]
        }
      ],
      "source": [
        "tokenizer        = transformers. AutoTokenizer. from_pretrained(\"bert-base-cased\") # GPT or BERT. 2 foundational approaches in Llm\n",
        "tokenizer_output = tokenizer(raw_inputs , padding=True , return_tensors=\"pt\")    # Numeric ids => as PYTORCH TENSORS\n",
        "\n",
        "print(tokenizer_output['input_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOah1DelE16O",
        "outputId": "971b498d-ccea-416e-f013-cc39da374354"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokenizer returns multiple things things => dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
            "Sentence Number => 1, Sentence = ['I', 'love', 'you', 'so', 'much'], \n",
            "\t input_ids \t=> tensor([ 101,  146, 1567, 1128, 1177, 1277,  102]), \n",
            "\t attention_mask => tensor([1, 1, 1, 1, 1, 1, 1])\n",
            "Sentence Number => 2, Sentence = ['I', 'hate', 'you'], \n",
            "\t input_ids \t=> tensor([ 101,  146, 4819, 1128,  102,    0,    0]), \n",
            "\t attention_mask => tensor([1, 1, 1, 1, 1, 0, 0])\n",
            "Sentence Number => 3, Sentence = ['you'], \n",
            "\t input_ids \t=> tensor([ 101, 1128,  102,    0,    0,    0,    0]), \n",
            "\t attention_mask => tensor([1, 1, 1, 0, 0, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "print(f'tokenizer returns multiple things things => {tokenizer_output.keys()}')\n",
        "\n",
        "index = 0\n",
        "while index < len(tokenizer_output['input_ids']):\n",
        "    print(f'Sentence Number => {index+1}, Sentence = {raw_inputs[index].split()}, ')\n",
        "    print(f\"\\t input_ids \\t=> { tokenizer_output['input_ids'][index]}, \\n\\t attention_mask => {tokenizer_output['attention_mask'][index]}\")\n",
        "    index = index + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPpho7KME16O"
      },
      "source": [
        "```\n",
        "Sentence Number => 1, Sentence =    ['I'    , 'love'    , 'you' , 'so'  , 'much'],\n",
        "\t input_ids \t=>      tensor(     [ 101   ,  146      , 1567  , 1128  , 1177      , 1277,  102    ]),\n",
        "\t attention_mask =>  tensor(     [1      , 1         , 1     , 1     , 1         , 1   , 1       ])\n",
        "\n",
        "Sentence Number => 2, Sentence =    ['I'    , 'hate'    , 'you'                         ],\n",
        "\t input_ids \t=>      tensor(     [ 101   ,  146      , 4819  , 1128  ,  102      ,    0,    0    ]),\n",
        "\t attention_mask =>  tensor(     [1      , 1         , 1     , 1     , 1         , 0     , 0])\n",
        "\n",
        "Sentence Number => 3, Sentence =    ['hi'                                                   ]  \n",
        "\t input_ids \t=>      tensor(     [  101  , 20844     ,   102 ,     0 ,     0     ,     0,     0]),\n",
        "\t attention_mask =>  tensor(     [1      , 1         , 1, 0  , 0     , 0         , 0])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orHMNDIoE16P"
      },
      "source": [
        "## 2. model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCqO8MeNE16P",
        "outputId": "659ea2b4-5e5e-4ad6-96d9-45feb8980ec6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model_general         = transformers. AutoModel.                         from_pretrained(\"bert-base-cased\")\n",
        "model_classification  = transformers. AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoCtTgcmE16Q",
        "outputId": "a64c2955-e3b7-4c80-f0ba-4a762abb6988"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model OUTPUT: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.5555, -0.3611],\n",
            "        [ 0.6966, -0.3005],\n",
            "        [ 0.6272, -0.2788]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None) \n"
          ]
        }
      ],
      "source": [
        "classification_output = model_classification( **tokenizer_output )\n",
        "\n",
        "print(f'Model OUTPUT: {classification_output} ' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnTOCUFaE16Q",
        "outputId": "712410cb-711e-40b9-9d8d-383ba5444b5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 3.5627e-01,  2.1760e-01, -2.5326e-01,  ..., -1.2633e-01,\n",
              "           7.3651e-01, -9.8767e-02],\n",
              "         [ 2.1338e-01,  6.1095e-02, -1.4929e-01,  ...,  4.3693e-01,\n",
              "           3.3071e-01,  3.0004e-01],\n",
              "         [-8.9151e-03, -1.7283e-01, -6.5382e-01,  ...,  4.8534e-01,\n",
              "           6.5441e-02,  3.9704e-01],\n",
              "         ...,\n",
              "         [ 6.3233e-01,  3.5286e-01, -4.8239e-01,  ...,  4.3351e-01,\n",
              "           5.1942e-01,  5.0280e-01],\n",
              "         [ 7.4279e-01, -3.6099e-02, -8.3125e-01,  ...,  1.7308e-01,\n",
              "           2.2512e-01, -4.9078e-02],\n",
              "         [ 3.3614e-01,  3.1221e-01, -1.1223e+00,  ...,  1.8383e-01,\n",
              "           1.2339e+00,  4.4745e-03]],\n",
              "\n",
              "        [[ 5.0739e-01,  2.7870e-01, -1.8380e-01,  ..., -2.7795e-01,\n",
              "           4.1159e-01, -3.7609e-01],\n",
              "         [ 4.3100e-01, -1.6551e-02,  1.1972e-01,  ...,  7.1019e-02,\n",
              "           3.0337e-01,  4.7959e-02],\n",
              "         [ 9.9891e-02,  1.4374e-01, -6.8824e-01,  ...,  5.1895e-02,\n",
              "           1.4580e-01,  2.8837e-01],\n",
              "         ...,\n",
              "         [ 9.7621e-01,  4.3272e-01, -8.1904e-01,  ..., -2.4840e-01,\n",
              "           7.7604e-01, -5.5987e-01],\n",
              "         [ 2.4276e-01,  2.7037e-01, -3.3893e-01,  ...,  1.6448e-01,\n",
              "           2.4892e-01, -3.9001e-01],\n",
              "         [ 8.1842e-02, -1.7333e-02, -5.0642e-01,  ...,  2.1858e-01,\n",
              "           5.3810e-01, -3.1143e-01]],\n",
              "\n",
              "        [[ 4.3282e-01,  8.0282e-02,  1.3320e-01,  ..., -2.1400e-01,\n",
              "           2.0411e-01, -1.4911e-01],\n",
              "         [ 9.5850e-01, -4.8482e-01,  4.8006e-01,  ..., -5.5579e-01,\n",
              "           2.9769e-01,  2.2213e-01],\n",
              "         [ 7.8869e-01, -3.8626e-02, -9.4578e-01,  ..., -7.6036e-02,\n",
              "           9.0401e-01, -2.6939e-01],\n",
              "         ...,\n",
              "         [ 4.7946e-01, -2.2006e-01, -7.7040e-02,  ...,  2.2510e-01,\n",
              "           1.1147e-01,  8.5901e-03],\n",
              "         [ 6.0579e-01, -2.3933e-01,  3.8685e-03,  ..., -1.0256e-01,\n",
              "           8.1206e-03, -2.4226e-01],\n",
              "         [ 5.9084e-01, -2.5220e-01,  1.0567e-03,  ..., -9.4803e-02,\n",
              "          -2.5085e-02, -2.5169e-01]]], grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.7418,  0.4758,  0.9999,  ...,  1.0000, -0.7724,  0.9931],\n",
              "        [-0.6141,  0.4634,  0.9999,  ...,  1.0000, -0.7861,  0.9952],\n",
              "        [-0.7076,  0.5115,  0.9999,  ...,  1.0000, -0.7737,  0.9938]],\n",
              "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_general( **tokenizer_output )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEj6gqoRE16Q"
      },
      "source": [
        "## 3. model output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aQH8QNAE16R",
        "outputId": "be306394-f062-4454-ae4e-c6ee3f49c1fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.5254, 0.4746],\n",
            "        [0.5081, 0.4919],\n",
            "        [0.5043, 0.4957]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# a , b -> a / (a + b) , b / (a + b)\n",
        "predictions = torch.nn.functional.softmax(classification_output.logits, dim=-1)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62Ez6lpJE16R"
      },
      "source": [
        "# Complete Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBTyMIx4E16R",
        "outputId": "72599f33-74d0-4c75-c169-c19f548058ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import transformers\n",
        "\n",
        "checkpoint = \"bert-base-cased\"\n",
        "tokenizer  = transformers.  AutoTokenizer.                        from_pretrained(checkpoint)\n",
        "model      = transformers.  AutoModelForSequenceClassification.   from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBXHALiaE16R",
        "outputId": "9d4a19d6-6f6a-4a74-9e4d-9d780f6f65c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.2870, -0.0723],\n",
            "        [-0.2221, -0.0587]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.4465, 0.5535],\n",
            "        [0.4592, 0.5408]], grad_fn=<SoftmaxBackward0>)\n",
            "{0: 'LABEL_0', 1: 'LABEL_1'}\n"
          ]
        }
      ],
      "source": [
        "raw_inputs = [\n",
        "    \"I love you so much\",   # 5 Words\n",
        "    \"screw you\",            # 2 Words\n",
        "]\n",
        "numeric_ids = tokenizer(raw_inputs , padding=True , return_tensors=\"pt\")    # Numeric ids => as PYTORCH TENSORS\n",
        "\n",
        "outputs = model(**numeric_ids)\n",
        "\n",
        "print(outputs.logits)\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "print(predictions)\n",
        "\n",
        "print(model.config.id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-t1tcfXoE16R"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}